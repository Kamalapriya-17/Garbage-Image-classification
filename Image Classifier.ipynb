{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57644d76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 'battery' â†’ 756 train, 189 test\n",
      "Class 'biological' â†’ 788 train, 197 test\n",
      "Class 'brown-glass' â†’ 485 train, 122 test\n",
      "Class 'cardboard' â†’ 712 train, 179 test\n",
      "Class 'clothes' â†’ 4260 train, 1065 test\n",
      "Class 'green-glass' â†’ 503 train, 126 test\n",
      "Class 'metal' â†’ 615 train, 154 test\n",
      "Class 'paper' â†’ 840 train, 210 test\n",
      "Class 'plastic' â†’ 692 train, 173 test\n",
      "Class 'shoes' â†’ 1581 train, 396 test\n",
      "Class 'trash' â†’ 557 train, 140 test\n",
      "Class 'white-glass' â†’ 620 train, 155 test\n",
      "Dataset split completed successfully!\n",
      "Running on: cpu\n",
      "\n",
      "ðŸ”¥ Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 485/485 [05:18<00:00,  1.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ” Train Accuracy: 0.5655\n",
      "â±ï¸ Epoch Time: 318.29 seconds\n",
      "\n",
      "ðŸ”¥ Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 485/485 [05:27<00:00,  1.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ” Train Accuracy: 0.6830\n",
      "â±ï¸ Epoch Time: 327.84 seconds\n",
      "\n",
      "ðŸ”¥ Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 485/485 [05:00<00:00,  1.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ” Train Accuracy: 0.7246\n",
      "â±ï¸ Epoch Time: 300.44 seconds\n",
      "\n",
      "ðŸ”¥ Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 485/485 [05:08<00:00,  1.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ” Train Accuracy: 0.7557\n",
      "â±ï¸ Epoch Time: 308.36 seconds\n",
      "\n",
      "ðŸ”¥ Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 485/485 [05:25<00:00,  1.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ” Train Accuracy: 0.7738\n",
      "â±ï¸ Epoch Time: 325.93 seconds\n",
      "\n",
      "ðŸ”¥ Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 485/485 [05:07<00:00,  1.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ” Train Accuracy: 0.7930\n",
      "â±ï¸ Epoch Time: 307.44 seconds\n",
      "\n",
      "ðŸ”¥ Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 485/485 [05:00<00:00,  1.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ” Train Accuracy: 0.8077\n",
      "â±ï¸ Epoch Time: 300.02 seconds\n",
      "\n",
      "ðŸ”¥ Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 485/485 [05:15<00:00,  1.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ” Train Accuracy: 0.8199\n",
      "â±ï¸ Epoch Time: 315.32 seconds\n",
      "\n",
      "ðŸ”¥ Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 485/485 [05:43<00:00,  1.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ” Train Accuracy: 0.8355\n",
      "â±ï¸ Epoch Time: 343.37 seconds\n",
      "\n",
      "ðŸ”¥ Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 485/485 [05:42<00:00,  1.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ” Train Accuracy: 0.8483\n",
      "â±ï¸ Epoch Time: 342.91 seconds\n"
     ]
    }
   ],
   "source": [
    "#1. IMPORTS\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models import mobilenet_v2, MobileNet_V2_Weights\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from PIL import Image \n",
    "\n",
    "#2. Use Faster Image Preprocessing (128Ã—128)\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(5),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "#3. Load Dataset (Faster DataLoader)\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "source_dir = \"garbage_classification\"       # your only folder\n",
    "dest_dir = \"dataset\"         # new split folder\n",
    "train_ratio = 0.8            # 80% training, 20% testing\n",
    "\n",
    "# Create output folders\n",
    "train_dir = os.path.join(dest_dir, \"train\")\n",
    "test_dir  = os.path.join(dest_dir, \"test\")\n",
    "\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "os.makedirs(test_dir,  exist_ok=True)\n",
    "\n",
    "# Loop through each class folder\n",
    "for class_name in os.listdir(source_dir):\n",
    "    class_path = os.path.join(source_dir, class_name)\n",
    "\n",
    "    if not os.path.isdir(class_path):\n",
    "        continue\n",
    "    \n",
    "    images = os.listdir(class_path)\n",
    "    random.shuffle(images)\n",
    "\n",
    "    split_idx = int(len(images) * train_ratio)\n",
    "    train_files = images[:split_idx]\n",
    "    test_files  = images[split_idx:]\n",
    "\n",
    "    # Create class folders inside train/test\n",
    "    os.makedirs(os.path.join(train_dir, class_name), exist_ok=True)\n",
    "    os.makedirs(os.path.join(test_dir, class_name),  exist_ok=True)\n",
    "\n",
    "    # Move files to train folder\n",
    "    for img in train_files:\n",
    "        shutil.copy(\n",
    "            os.path.join(class_path, img),\n",
    "            os.path.join(train_dir, class_name, img)\n",
    "        )\n",
    "\n",
    "    # Move files to test folder\n",
    "    for img in test_files:\n",
    "        shutil.copy(\n",
    "            os.path.join(class_path, img),\n",
    "            os.path.join(test_dir, class_name, img)\n",
    "        )\n",
    "\n",
    "    print(f\"Class '{class_name}' â†’ {len(train_files)} train, {len(test_files)} test\")\n",
    "\n",
    "print(\"Dataset split completed successfully!\")\n",
    "train_data = datasets.ImageFolder(\"dataset/train\", transform=train_transforms)\n",
    "test_data  = datasets.ImageFolder(\"dataset/test\", transform=test_transforms)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True, num_workers=4)\n",
    "test_loader  = DataLoader(test_data, batch_size=32, shuffle=False, num_workers=4)\n",
    "\n",
    "class_names = train_data.classes\n",
    "\n",
    "#4. FAST Model (MobileNetV2)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Running on:\", device)\n",
    "\n",
    "class SmallCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Conv2d(16, 32, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Conv2d(32, 64, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "        self.fc = nn.Linear(64 * 16 * 16, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model1 = SmallCNN(num_classes=len(class_names)).to(device)\n",
    "\n",
    "# Replace classification layer\n",
    "\n",
    "model1 = model1.to(device)\n",
    "\n",
    "#5. Training Setup\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model1.parameters(), lr=0.001)\n",
    "epochs = 10\n",
    "\n",
    "#6. SUPER-FAST TRAIN LOOP (with progress bar)\n",
    "for epoch in range(epochs):\n",
    "    print(f\"\\nðŸ”¥ Epoch {epoch+1}/{epochs}\")\n",
    "    model1.train()\n",
    "\n",
    "    start = time.time()\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    for images, labels in tqdm(train_loader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model1(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total_correct += (predicted == labels).sum().item()\n",
    "        total_samples += labels.size(0)\n",
    "\n",
    "    train_acc = total_correct / total_samples\n",
    "    print(f\"âœ” Train Accuracy: {train_acc:.4f}\")\n",
    "    print(f\"â±ï¸ Epoch Time: {time.time() - start:.2f} seconds\")\n",
    "\n",
    "#8. CONFUSION MATRIX + VISUALIZATION\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "model1.eval()\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model1(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "        y_pred.extend(predicted.cpu().numpy())\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "def predict_image(image_path, model):\n",
    "    model.eval()\n",
    "\n",
    "    img = Image.open(image_path).convert(\"RGB\")\n",
    "    transform = test_transforms\n",
    "\n",
    "    img_t = transform(img).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(img_t)\n",
    "        probabilities = torch.softmax(outputs, dim=1)\n",
    "        confidence, predicted = torch.max(probabilities, 1)\n",
    "\n",
    "    class_name = class_names[predicted.item()]\n",
    "    return class_name, confidence.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddc764d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tqdm\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\murugan\\appdata\\roaming\\python\\python313\\site-packages (from tqdm) (0.4.6)\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: tqdm\n",
      "Successfully installed tqdm-4.67.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757d249f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_training(history):\n",
    "    train_losses = history['train_loss']\n",
    "    val_losses = history['val_loss']\n",
    "    train_acc = history['train_acc']\n",
    "    val_acc = history['val_acc']\n",
    "\n",
    "    epochs = range(1, len(train_losses) + 1)\n",
    "\n",
    "    plt.figure(figsize=(14,5))\n",
    "\n",
    "    # ---- Loss Plot ----\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(epochs, train_losses, label='Train Loss')\n",
    "    plt.plot(epochs, val_losses, label='Val Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training vs Validation Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    # ---- Accuracy Plot ----\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(epochs, train_acc, label='Train Accuracy')\n",
    "    plt.plot(epochs, val_acc, label='Val Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Training vs Validation Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10847fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: white-glass, Confidence: 0.6022\n"
     ]
    }
   ],
   "source": [
    "%write new.\n",
    "\n",
    "predicted_class, confidence = predict_image(\"test.jpg\", model)\n",
    "print(f\"Predicted class: {predicted_class}, Confidence: {confidence:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728461a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
